{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ntytu8-WwfG"
   },
   "source": [
    "# Set up Google Colab\n",
    "\n",
    "This means mounting drive and importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1331,
     "status": "ok",
     "timestamp": 1625702724289,
     "user": {
      "displayName": "James Eckstein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSkbwuGkSVFXmpY_K5aXDzWl4lccRS01YB-YMb=s64",
      "userId": "05032552484174298418"
     },
     "user_tz": 360
    },
    "id": "Z5laSkra8ozA",
    "outputId": "1f491456-31a2-4a54-8490-f08d7cda16ec"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Enter the foldername in your Drive where you have saved the unzipped\n",
    "# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
    "FOLDERNAME = 'Lab/Grain-U-Net'\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# Now that we've mounted your Drive, this ensures that\n",
    "# the Python interpreter of the Colab VM can load\n",
    "# python files from within it.\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# This downloads the CIFAR-10 dataset to your Drive\n",
    "# if it doesn't already exist.\n",
    "\n",
    "# %cd drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
    "# !bash get_datasets.sh\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME\n",
    "#!pip install\n",
    "#4/1AY0e-g5h4eZedG3k6mfdIj0OYbR717PFyEhKuxK5PidsrBbPRxi8fge6E3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4020,
     "status": "ok",
     "timestamp": 1625702201898,
     "user": {
      "displayName": "James Eckstein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSkbwuGkSVFXmpY_K5aXDzWl4lccRS01YB-YMb=s64",
      "userId": "05032552484174298418"
     },
     "user_tz": 360
    },
    "id": "k9dylqdk8nmu"
   },
   "outputs": [],
   "source": [
    "from model import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzmssZqc8nmz"
   },
   "source": [
    "# Train your Unet with membrane data\n",
    "membrane data is in folder membrane/, it is a binary classification task.\n",
    "\n",
    "The input shape of image and mask are the same :(batch_size,rows,cols,channel = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYRADonH8nm0"
   },
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCLKtQBo8nm1",
    "outputId": "2328530b-87f8-4d29-f77d-7c81d879cff9"
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.00,\n",
    "                    height_shift_range=0.00,\n",
    "                    shear_range=0.00,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(2,'data/train','image','label',data_gen_args,save_to_dir = 'data/train/aug')\n",
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('unet_grain.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(myGene,steps_per_epoch=2000,epochs=5,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awJicPBV8nm1"
   },
   "source": [
    "### Train with npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOjJVddt8nm2"
   },
   "outputs": [],
   "source": [
    "#imgs_train,imgs_mask_train = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
    "#model.fit(imgs_train, imgs_mask_train, batch_size=2, nb_epoch=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1624751299099,
     "user": {
      "displayName": "James Eckstein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSkbwuGkSVFXmpY_K5aXDzWl4lccRS01YB-YMb=s64",
      "userId": "05032552484174298418"
     },
     "user_tz": 360
    },
    "id": "hexeg4IiuTvs",
    "outputId": "36357a92-abd2-42ae-a303-a03631e27ce7"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC9fh6Jn8nm2"
   },
   "source": [
    "### test your model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99724,
     "status": "ok",
     "timestamp": 1624858636487,
     "user": {
      "displayName": "James Eckstein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSkbwuGkSVFXmpY_K5aXDzWl4lccRS01YB-YMb=s64",
      "userId": "05032552484174298418"
     },
     "user_tz": 360
    },
    "id": "BdvX_FQJ8nm2",
    "outputId": "1c539823-b627-45d2-ab35-c2112e920d44"
   },
   "outputs": [],
   "source": [
    "testGene = testGenerator(\"data/test\")\n",
    "model = unet()\n",
    "model.load_weights(\"unet_grain.hdf5\")\n",
    "results = 255 * model.predict_generator(testGene, 23, verbose=1)\n",
    "saveResult(\"data/test\", results.astype('uint8'))\n",
    "# print(results.shape)\n",
    "# io.imshow(results[22, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w1CEhlEXxi6"
   },
   "source": [
    "# Small Post Processing Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sis-WIcXYp7W"
   },
   "source": [
    "This next thing is just to visualize what the processing is doing before applying it to all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1624859319216,
     "user": {
      "displayName": "James Eckstein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSkbwuGkSVFXmpY_K5aXDzWl4lccRS01YB-YMb=s64",
      "userId": "05032552484174298418"
     },
     "user_tz": 360
    },
    "id": "7P3IQNMcXxJ0",
    "outputId": "fe59d796-2606-4110-ffe3-1a75c6593fb8"
   },
   "outputs": [],
   "source": [
    "from skimage import data, io, filters, morphology\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imsubplot(ax, im, cmap=\"gray\", title=None):\n",
    "    ax.imshow(im, cmap=cmap)\n",
    "    ax.axis(\"off\")\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "def post_process(path, thresh=255, verbose=False):\n",
    "    image = io.imread(path)\n",
    "    threshold = np.zeros(image.shape)\n",
    "    threshold[image < thresh] = 1\n",
    "    skeleton = morphology.skeletonize(threshold)\n",
    "    \n",
    "    if verbose:\n",
    "        fig, (a, b, c) = plt.subplots(ncols=3)\n",
    "        \n",
    "        imsubplot(a, image, title='UNET Output')\n",
    "        imsubplot(b, threshold, title='Threshold')\n",
    "        imsubplot(c, skeleton, title='Skeleton')\n",
    "        plt.show()\n",
    "    else:\n",
    "        return skeleton\n",
    "\n",
    "post_process('data/test/0_predict.png', thresh=250, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnXY_X1UY6AB"
   },
   "source": [
    "#### This is to apply this processing to all the boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_h72d6UY5Rm"
   },
   "outputs": [],
   "source": [
    "test_n = 23\n",
    "test_dir = 'data/test/'\n",
    "\n",
    "for i in range(test_n):\n",
    "    im_path = f'{test_dir}{i}_predict.png'\n",
    "    skel = 255 * post_process(im_path, thresh=250)\n",
    "    io.imsave(f'{test_dir}{i}_processed.png', skel.astype('uint8')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR6xzMBPcaw2"
   },
   "source": [
    "# Overlay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SalLaUI4c-1A"
   },
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "\n",
    "test_n = 23\n",
    "test_dir = 'data/test/'\n",
    "\n",
    "for i in range(test_n):\n",
    "    raw_img = io.imread(f'{test_dir}{i}.png')\n",
    "    sk_img = io.imread(f'{test_dir}{i}_processed.png')\n",
    "    sk_img = 255 * transform.resize(sk_img, raw_img.shape, anti_aliasing=False)\n",
    "    fusion_img = np.zeros((raw_img.shape[0], raw_img.shape[1], 3), dtype=int)\n",
    "    fusion_img[:, :, 0] = raw_img\n",
    "    fusion_img[:, :, 1] = raw_img\n",
    "    fusion_img[:, :, 2] = raw_img\n",
    "    fusion_img[sk_img > 0, 0] = 255\n",
    "\n",
    "    io.imsave(f'{test_dir}{i}_overlaid.png', fusion_img.astype('uint8')) \n",
    "#    io.imshow(fusion_img)\n",
    "#    io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVtddQFjoXsP"
   },
   "source": [
    "# Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 11:\t 205932 \t 81.7514886859865\n",
      "Image 1:\t 17453 \t 5.896283783783784\n",
      "Image 2:\t 2642 \t 1.110550651534258\n",
      "Image 7:\t 108598 \t 36.63900134952767\n",
      "Image 4:\t 166350 \t 85.2202868852459\n",
      "Image 3:\t 36192 \t 14.570048309178745\n",
      "Image 5:\t 55402 \t 19.562853107344633\n",
      "Image 0:\t 33696 \t 14.302207130730052\n",
      "Image 9:\t 45601 \t 18.052652414885195\n",
      "Image 6:\t 32097 \t 14.88038942976356\n",
      "Image 12:\t 36834 \t 17.674664107485604\n",
      "Image 8:\t 38225 \t 14.534220532319392\n",
      "Image 10:\t 65879 \t 22.53043775649795\n"
     ]
    }
   ],
   "source": [
    "from chi2test import find_chi2\n",
    "from skimage import io, transform\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "test_dir = 'data/test/'\n",
    "traced_dir = 'data/test/key/'\n",
    "traced_names = os.listdir(traced_dir)\n",
    "traced = np.char.strip(traced_names, '.png')\n",
    "\n",
    "for key in traced:\n",
    "    ml_img = io.imread(test_dir + key + '_processed.png')\n",
    "    key_img = transform.resize(io.imread(traced_dir + key + '.png'), ml_img.shape)\n",
    "\n",
    "    if np.min(key_img) != 0 or np.max(key_img) != 255:\n",
    "        key_img -= np.min(key_img)\n",
    "        key_img = np.round(key_img * (255 / np.max(key_img)))\n",
    "    key_img = np.max(key_img) - key_img\n",
    "\n",
    "    results = find_chi2(ml_img, key_img, out_dict=True)\n",
    "    print(f'Image {key}:\\t {results[\"chi2\"]} \\t {results[\"avg_chi2\"]}')\n",
    "    '''\n",
    "    fuse_size = np.maximum(key_img.shape, ml_img.shape)\n",
    "    def fuse(out, img, offset_x=0, offset_y=0):\n",
    "        buf_x = out.shape[0] - img.shape[0]\n",
    "        buf_y = out.shape[1] - img.shape[1]\n",
    "        img = np.round(img * (255 / np.max(img)))\n",
    "        out[buf_x//2 + offset_x : -buf_x//2 + offset_x, buf_y//2 + offset_y : -buf_y//2 + offset_y] = img\n",
    "\n",
    "    fuse_img = np.zeros((fuse_size[0] + 2, fuse_size[1] + 2, 3), dtype=int)\n",
    "    fuse(fuse_img[:,:,0], ml_img)\n",
    "    fuse(fuse_img[:,:,1], key_img)\n",
    "    io.imshow(fuse_img)\n",
    "    io.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broken Chi2 Alignment (Don't use, the descent function is really bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "executionInfo": {
     "elapsed": 906,
     "status": "error",
     "timestamp": 1625702730182,
     "user": {
      "displayName": "James Eckstein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSkbwuGkSVFXmpY_K5aXDzWl4lccRS01YB-YMb=s64",
      "userId": "05032552484174298418"
     },
     "user_tz": 360
    },
    "id": "esr9-E2Ao6NX",
    "outputId": "b9f1e760-2f8b-48fa-f472-c4cdadf6c559"
   },
   "outputs": [],
   "source": [
    "from chi2test import *\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "\n",
    "traced_n = 13\n",
    "traced_dir = 'data/test/key/'\n",
    "\n",
    "ml_img = io.imread('data/test/5_processed.png')\n",
    "key_img = transform.resize(io.imread('data/test/key/5.png'), ml_img.shape)\n",
    "\n",
    "if np.min(ml_img) != 0 or np.max(ml_img) != 255:\n",
    "    ml_img -= np.min(ml_img)\n",
    "    ml_img = np.round(ml_img * (255 / np.max(ml_img)))\n",
    "        \n",
    "if np.min(key_img) != 0 or np.max(key_img) != 255:\n",
    "    key_img -= np.min(key_img)\n",
    "    key_img = np.round(key_img * (255 / np.max(key_img)))\n",
    "    \n",
    "key_img = 255 - key_img\n",
    "\n",
    "io.imshow(key_img)\n",
    "io.show()\n",
    "\n",
    "io.imshow(ml_img)\n",
    "io.show()\n",
    "\n",
    "results = chi2_align(ml_img, key_img)\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(find_chi2(ml_img, key_img))\n",
    "\n",
    "offset_x = int(results[\"x\"])\n",
    "offset_y = int(results[\"y\"])\n",
    "fuse_size = np.maximum(key_img.shape, ml_img.shape)\n",
    "fuse_size[0] += 2 * offset_x + 2\n",
    "fuse_size[1] += 2 * offset_y + 2\n",
    "\n",
    "def fuse(out, img, offset_x=0, offset_y=0):\n",
    "    buf_x = out.shape[0] - img.shape[0]\n",
    "    buf_y = out.shape[1] - img.shape[1]\n",
    "    img = np.round(img * (255 / np.max(img)))\n",
    "    print(buf_x//2, buf_y//2)\n",
    "    out[buf_x//2 + offset_x : -buf_x//2 + offset_x, buf_y//2 + offset_y : -buf_y//2 + offset_y] = img\n",
    "\n",
    "fuse_img = np.zeros((fuse_size[0], fuse_size[1], 3), dtype=int)\n",
    "print(fuse_img.shape)\n",
    "fuse(fuse_img[:,:,0], ml_img, offset_x, offset_y)\n",
    "print(fuse_img.shape)\n",
    "fuse(fuse_img[:,:,1], key_img)\n",
    "\n",
    "io.imshow(fuse_img)\n",
    "io.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
