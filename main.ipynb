{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ntytu8-WwfG"
   },
   "source": [
    "# Set up Google Colab\n",
    "\n",
    "This means mounting drive and importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3100,
     "status": "ok",
     "timestamp": 1649458336603,
     "user": {
      "displayName": "James Eckstein",
      "userId": "05032552484174298418"
     },
     "user_tz": 300
    },
    "id": "Z5laSkra8ozA",
    "outputId": "d7ca83ee-845f-463c-9836-babe19fb39fa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "FOLDERNAME = 'Lab/Grain-U-Net'\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))\n",
    "sys.path.append('/content/drive/MyDrive/{}/src'.format(FOLDERNAME))\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME\n",
    "\n",
    "!pip install -q plantcv\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport -tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzmssZqc8nmz"
   },
   "source": [
    "# Train\n",
    "\n",
    "Currently we have two ways of doing this, one with a keras Sequence and one with ImageDataGenerator. It isn't obvious which of these is better, \n",
    "\n",
    "the Sequence is:\n",
    "- Less opaque\n",
    "- Easier to debug (for me at least)\n",
    "- Pretty straight forward and customizable\n",
    "\n",
    "And the ImageDataGenerator is:\n",
    "- Fewer lines (sort of)\n",
    "- It has built in data augmentation\n",
    "- Faster (since its all written by pros)\n",
    "- Doesn't really seem super well suited to like semantic segmentation, but its probably fine\n",
    "\n",
    "So for now, I'm spending most of my time with the Sequence approach, but both are good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8T4RUTKKsoRK"
   },
   "source": [
    "## Train With Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFxQqYZbsoRL"
   },
   "source": [
    "**Importing the names of all the files we want to train with**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "train_dir = Path('data/train_atarashii_256')\n",
    "\n",
    "input_names = list(train_dir.glob('**/image/*.png'))\n",
    "label_names = list(train_dir.glob('**/label/*.png'))\n",
    "\n",
    "print(f\"Found {len(input_names)} samples and {len(label_names)} tracings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jT3QgTqyuegg"
   },
   "source": [
    "**Making Sequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 712,
     "status": "ok",
     "timestamp": 1648847066957,
     "user": {
      "displayName": "James Eckstein",
      "userId": "05032552484174298418"
     },
     "user_tz": 300
    },
    "id": "H0P1QvUHsoRM",
    "outputId": "a5fb34c5-748a-425d-cd9c-b7f1ed5ea00c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src import GrainSequence\n",
    "import random\n",
    "\n",
    "validation_samples = len(input_names) // 10\n",
    "batch_size = 5\n",
    "\n",
    "random.Random(1337).shuffle(input_names)\n",
    "random.Random(1337).shuffle(label_names)\n",
    "\n",
    "train_input = input_names[:-validation_samples]\n",
    "train_label = label_names[:-validation_samples]\n",
    "train_gen = GrainSequence(batch_size, (256,256), train_input, train_label)\n",
    "\n",
    "valid_input = input_names[-validation_samples:]\n",
    "valid_label = label_names[-validation_samples:]\n",
    "valid_gen = GrainSequence(batch_size, (256,256), valid_input, valid_label)\n",
    "\n",
    "print(f\"Training set size: {len(train_input)}, {len(train_gen)} batches\")\n",
    "print(f\"Validation set size: {len(valid_input)}, {len(valid_gen)} batches\")\n",
    "\n",
    "if False:\n",
    "    _ = [print(f'{ind}:\\n{i}\\n{l}\\n\\n') for ind, (i, l) in enumerate(zip(train_input, train_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "yrhEI1FasoRN",
    "outputId": "1c653af6-ff87-4289-a0c6-535673d40328"
   },
   "outputs": [],
   "source": [
    "from src import get_unet\n",
    "from tensorflow import keras\n",
    "\n",
    "model = get_unet(input_size = (256, 256, 1))\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint('unet_grain.hdf5', monitor='loss', verbose=1, save_best_only=False)\n",
    "history = model.fit(\n",
    "    train_gen, \n",
    "    steps_per_epoch=len(train_gen), \n",
    "    epochs=30, \n",
    "    callbacks=[model_checkpoint], \n",
    "     validation_data=valid_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1648839595762,
     "user": {
      "displayName": "James Eckstein",
      "userId": "05032552484174298418"
     },
     "user_tz": 300
    },
    "id": "GlcQzaDoNFQd",
    "outputId": "214e4c30-48af-42a1-9fad-da5bf9950780"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "valid_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10,5), facecolor='White')\n",
    "\n",
    "plt.title(\"Loss With Pre Augmentation and Full Dataset (b5, s59)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(valid_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Channel Testing\n",
    "\n",
    "So the idea is that we'll use this file structure and point to the test_dir\n",
    "````\n",
    "test_dir\n",
    "├── FOV1\n",
    "│   ├── predict\n",
    "│   │   ├── img1.png\n",
    "│   │   ├── img2.png\n",
    "│   │   ├── img3.png\n",
    "│   │   └── img4.png\n",
    "│   ├── raw\n",
    "│   │   ├── img1.png\n",
    "│   │   ├── img2.png\n",
    "│   │   ├── img3.png\n",
    "│   │   └── img4.png\n",
    "│   └── unet_skel.png\n",
    "├── FOV2\n",
    "│   ├── predict\n",
    "│   │   ├── img1.png\n",
    "│   │   └── img2.png\n",
    "│   ├── raw\n",
    "│   │   ├── img1.png\n",
    "│   │   └── img2.png\n",
    "│   └── unet_skel.png\n",
    "└── FOV3\n",
    "    ├── predict\n",
    "    │   ├── img1.png\n",
    "    │   ├── img2.png\n",
    "    │   └── img3.png\n",
    "    ├── raw\n",
    "    │   ├── img1.png\n",
    "    │   ├── img2.png\n",
    "    │   └── img3.png\n",
    "    └── unet_skel.png\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "from src import get_unet, image_generator\n",
    "import numpy as np\n",
    "\n",
    "target_size = (768,768)\n",
    "test_dir = Path('data/test_Cu/')\n",
    "\n",
    "paths = list(test_dir.glob('*/raw/*'))\n",
    "print(f'{len(paths)} images found')\n",
    "img_gen = image_generator(paths, target_size=target_size)\n",
    "\n",
    "model = get_unet(input_size=(target_size + (1,)))\n",
    "model.load_weights(\"results/nouveaux256_aug_b5-s53-e66.hdf5\")\n",
    "results = 255 * model.predict(img_gen, steps=len(paths), verbose=1)\n",
    "\n",
    "assert len(paths) == len(results), 'Not all the files ran'\n",
    "\n",
    "for ind, path in enumerate(paths): \n",
    "    save_dir = path.parents[1] / 'predict'\n",
    "    if not save_dir.is_dir():\n",
    "        print('made dir')\n",
    "        save_dir.mkdir()\n",
    "        \n",
    "    save_path = save_dir / path.with_suffix('.png').name\n",
    "    result = results[ind, :, :, 0]\n",
    "    \n",
    "    print(f\"\\nSaving to {save_path}\")\n",
    "    print(f\"Min: {np.min(result)}, Max: {np.max(result)}, Shape: {result.shape}\")\n",
    "    io.imsave(save_path, result.astype('uint8'))\n",
    "    if ind == 0:\n",
    "        io.imshow(result)\n",
    "        io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w1CEhlEXxi6"
   },
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_h72d6UY5Rm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skimage import io\n",
    "from src import post_process\n",
    "\n",
    "if 'test_dir' not in locals():\n",
    "    test_dir = Path('data/test_Cu/')\n",
    "\n",
    "process_args = {\n",
    "        'compilation': 'max',\n",
    "        'liberal_thresh': 195,\n",
    "        'conservative_thresh': 135,\n",
    "        'invert_double_thresh': True,\n",
    "        'n_dilations': 2,\n",
    "        'min_grain_area': 300,\n",
    "        'prune_size': 100,\n",
    "        'out_dict': True\n",
    "}\n",
    "    \n",
    "for FOV in test_dir.glob('*'):\n",
    "    if not (FOV / 'predict').is_dir():\n",
    "        continue\n",
    "    \n",
    "    imgs = np.array([])\n",
    "    for fname in FOV.glob(\"predict/*.png\"):\n",
    "        if not fname.is_file(): continue\n",
    "        \n",
    "        img = io.imread(fname)\n",
    "        if len(img.shape) > 2:\n",
    "            img = img[:,:,0]\n",
    "            \n",
    "        if len(imgs) == 0:\n",
    "            imgs = img\n",
    "        else:\n",
    "            imgs = np.dstack((imgs,img))\n",
    "               \n",
    "    data = post_process(imgs, **process_args)\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    from src.visual_tools import *\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15,8))\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    sub_plot(axes[0,0], data['compiled'], title='Min (logical or) Combined Image')\n",
    "    sub_plot(axes[0,1], data['double_thresh'], title='Double Thresholded Combined Image')\n",
    "    sub_plot(axes[0,2], data['dilated'], title='Dilated')\n",
    "    sub_plot(axes[1,2], data['closed'], title='Fill Holes')\n",
    "\n",
    "    sub_plot(axes[1,1], data['skeleton'], title='Double Threshold Skeleton')\n",
    "    sub_plot(axes[1,0], data['pruned_skeleton'], title='Pruned Skeleton')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    io.imsave(FOV / 'unet_max_compiled.png', data['compiled'].astype('uint8'))\n",
    "    print(f'Saving to: {FOV / \"unet_skel.png\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR6xzMBPcaw2"
   },
   "source": [
    "## Overlay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 21761,
     "status": "error",
     "timestamp": 1643051708537,
     "user": {
      "displayName": "James Eckstein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSkbwuGkSVFXmpY_K5aXDzWl4lccRS01YB-YMb=s64",
      "userId": "05032552484174298418"
     },
     "user_tz": 360
    },
    "id": "SalLaUI4c-1A",
    "outputId": "5d42cf68-b102-4909-c259-0b3103da2ccd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "if 'test_n' not in locals():\n",
    "    test_n = 1\n",
    "    test_dir = 'data/test/'\n",
    "\n",
    "for i in range(test_n):\n",
    "    i = i + 1\n",
    "    raw_img = io.imread(f'{test_dir}0{i}.png')\n",
    "    sk_img = io.imread(f'{test_dir}{i}_processed.png')\n",
    "    sk_img = 255 * transform.resize(sk_img, raw_img.shape, anti_aliasing=False)\n",
    "    fusion_img = np.zeros((raw_img.shape[0], raw_img.shape[1], 3), dtype=int)\n",
    "    fusion_img[:, :, 0] = raw_img\n",
    "    fusion_img[:, :, 1] = raw_img\n",
    "    fusion_img[:, :, 2] = raw_img\n",
    "    fusion_img[sk_img > 0, 0] = 255\n",
    "    if os.path.isfile(f'{test_dir}key/{i}.png'):\n",
    "        ht_img = io.imread(f'{test_dir}key/{i}.png')\n",
    "        ht_img = 255 - (255 * transform.resize(ht_img, raw_img.shape, anti_aliasing=False))\n",
    "        fusion_img[ht_img > 0, 1] = 255\n",
    "#        io.imshow(fusion_img)\n",
    "#        io.show()\n",
    "\n",
    "    io.imsave(f'{test_dir}{i}_overlaid.png', fusion_img.astype('uint8')) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jENaS3uhwUV9"
   },
   "source": [
    "# Model Evaluation Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ym5bKgKwG1rt"
   },
   "source": [
    "## Intersection Over Union (IOU)\n",
    "This test should find what percent of the predicted grain boundary (pred) matched the actual hand traced boundary (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3cKUkLxUl4G"
   },
   "source": [
    "`iou_test.find_iou(pred, ref)` \n",
    "This function finds the mean IOU between `pred` and `ref`. It does this by matching each grain in a traced (`ref`) image with a grain in the corresponding predicted (`pred`) image and calculating the Jaccard similarity index between them. It then takes the mean of all these Jaccard indicies to find the final mean iou of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5802,
     "status": "ok",
     "timestamp": 1629658985805,
     "user": {
      "displayName": "James Eckstein",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjSkbwuGkSVFXmpY_K5aXDzWl4lccRS01YB-YMb=s64",
      "userId": "05032552484174298418"
     },
     "user_tz": 300
    },
    "id": "S-f5FWreHFYk",
    "outputId": "33353927-5033-46a8-c667-222ee709763d"
   },
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "from src.analysis import find_iou\n",
    "import importlib, os\n",
    "importlib.reload(iou_test)\n",
    "\n",
    "if 'test_n' in locals():\n",
    "    test_dir = 'data/test/'\n",
    "    traced_dir = 'data/test/key/'\n",
    "\n",
    "traced_dir = test_dir + 'key/'\n",
    "traced_names = np.sort(os.listdir(traced_dir))\n",
    "traced = np.char.strip(traced_names, '.png')\n",
    "\n",
    "results = np.array([], dtype=np.float64)\n",
    "\n",
    "for key in traced:\n",
    "    ml_img = io.imread(test_dir + key + '_processed.png') / 255\n",
    "    ml_img = 1 - ml_img\n",
    "#    ml_img = io.imread(test_dir + key + '_predict.png') / 255\n",
    "    key_img = transform.resize(io.imread(traced_dir + key + '.png'), ml_img.shape)\n",
    "    key_img = key_img > 0.9\n",
    "    \n",
    "    iou = find_iou(ml_img, key_img, verbose=False)\n",
    "    results = np.append(results, iou)\n",
    "    print(f' - img {key} \\t Mean IOU: {iou}')\n",
    "    \n",
    "print(f'\\nMean Mean IOU = {np.mean(results)}\\nMedian Mean IOU = {np.median(results)}\\n\\n')\n",
    "print(f'Max Mean IOU = {np.max(results)}, Min Mean IOU = {np.min(results)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVtddQFjoXsP"
   },
   "source": [
    "## Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCTzHcjCTHIt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from chi2test import find_chi2\n",
    "from skimage import io, transform\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "test_dir = 'data/test/'\n",
    "traced_dir = 'data/test/key/'\n",
    "traced_names = np.sort(os.listdir(traced_dir))\n",
    "traced = np.char.strip(traced_names, '.png')\n",
    "\n",
    "chi2_dtype = [('img', (np.str_, 10)), ('chi2', np.float64), ('avg_chi2', np.float64)]\n",
    "results = np.array([], dtype=chi2_dtype)\n",
    "\n",
    "for key in traced:\n",
    "    ml_img = io.imread(test_dir + key + '_processed.png')\n",
    "    key_img = transform.resize(io.imread(traced_dir + key + '.png'), ml_img.shape)\n",
    "\n",
    "    if np.min(key_img) != 0 or np.max(key_img) != 255:\n",
    "        key_img -= np.min(key_img)\n",
    "        key_img = np.round(key_img * (255 / np.max(key_img)))\n",
    "    key_img = np.max(key_img) - key_img\n",
    "    \n",
    "    result = find_chi2(ml_img, key_img, out_dict=True)\n",
    "    results = np.append(results, \\\n",
    "                np.array([(key, result[\"chi2\"], result[\"avg_chi2\"])], dtype=chi2_dtype))\n",
    "    print(f'- img: {key} \\t chi2: {result[\"chi2\"]} \\t avg_chi2: {result[\"avg_chi2\"]} \\t median_r2: {result[\"median_r2\"]}')\n",
    "\n",
    "print(f'\\nAverage chi2: {np.mean(results[\"chi2\"])}\\nAverage avg_chi2: {np.mean(results[\"avg_chi2\"])}\\nMedian chi2: {np.median(results[\"chi2\"])}')\n",
    "print(f'Max chi2: {np.max(results[\"chi2\"])}\\nMin chi2: {np.min(results[\"chi2\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziK9P9USTHIv"
   },
   "source": [
    "## Chi2 Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esr9-E2Ao6NX"
   },
   "outputs": [],
   "source": [
    "from chi2test import *\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "\n",
    "traced_n = 13\n",
    "traced_dir = 'data/test/key/'\n",
    "\n",
    "ml_img = io.imread('data/test/5_processed.png')\n",
    "key_img = transform.resize(io.imread('data/test/key/5.png'), ml_img.shape)\n",
    "\n",
    "if np.min(ml_img) != 0 or np.max(ml_img) != 255:\n",
    "    ml_img -= np.min(ml_img)\n",
    "    ml_img = np.round(ml_img * (255 / np.max(ml_img)))\n",
    "        \n",
    "if np.min(key_img) != 0 or np.max(key_img) != 255:\n",
    "    key_img -= np.min(key_img)\n",
    "    key_img = np.round(key_img * (255 / np.max(key_img)))\n",
    "    \n",
    "key_img = 255 - key_img\n",
    "\n",
    "io.imshow(key_img)\n",
    "io.show()\n",
    "\n",
    "io.imshow(ml_img)\n",
    "io.show()\n",
    "\n",
    "results = chi2_align(ml_img, key_img)\n",
    "\n",
    "print(results)\n",
    "\n",
    "print(find_chi2(ml_img, key_img))\n",
    "\n",
    "offset_x = int(results[\"x\"])\n",
    "offset_y = int(results[\"y\"])\n",
    "fuse_size = np.maximum(key_img.shape, ml_img.shape)\n",
    "fuse_size[0] += 2 * abs(offset_x) + 2\n",
    "fuse_size[1] += 2 * abs(offset_y) + 2\n",
    "\n",
    "def fuse(out, img, offset_x=0, offset_y=0):\n",
    "    buf_x = out.shape[0] - img.shape[0]\n",
    "    buf_y = out.shape[1] - img.shape[1]\n",
    "    img = np.round(img * (255 / np.max(img)))\n",
    "    x_low = buf_x//2 + offset_x\n",
    "    y_low = buf_y//2 + offset_y\n",
    "    x_high = -buf_x//2 + offset_x\n",
    "    y_high = -buf_y//2 + offset_y\n",
    "    print(x_low, y_low, x_high, y_high)\n",
    "    if (x_high > -1):\n",
    "        x_high = x_low + img.shape[0]\n",
    "    if (y_high > -1):\n",
    "        y_high = y_low + img.shape[1]\n",
    "    out[x_low : x_high, y_low : y_high] = img\n",
    "\n",
    "fuse_img = np.zeros((fuse_size[0], fuse_size[1], 3), dtype=int)\n",
    "print(fuse_img.shape)\n",
    "fuse(fuse_img[:,:,0], ml_img, offset_x, offset_y)\n",
    "print(fuse_img.shape)\n",
    "fuse(fuse_img[:,:,1], key_img)\n",
    "\n",
    "io.imshow(fuse_img)\n",
    "io.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [
    "yYRADonH8nm0",
    "SOes-E73s-n-",
    "jENaS3uhwUV9",
    "ym5bKgKwG1rt",
    "rVtddQFjoXsP",
    "ziK9P9USTHIv"
   ],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
